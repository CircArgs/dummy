from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_list_tools(client):
    with patch('httpx.AsyncClient', new_callable=AsyncMock) as mock_client:
        mock_instance = mock_client.return_value
        mock_instance.__aenter__.return_value = mock_instance
        mock_instance.__aexit__.return_value = AsyncMock()
        
        # Mock the GET request response
        mock_instance.get.return_value.json = AsyncMock(return_value=["tool1", "tool2"])
        mock_instance.get.return_value.raise_for_status = AsyncMock()

        # Call the method
        tools = await client.list_tools()
        
        # Assertions
        assert tools == ["tool1", "tool2"]
        mock_instance.get.assert_called_once_with("http://testserver/list_tools")


python -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m uvicorn main:app --reload --host 0.0.0.0 --port 8000

---

## **1. Pipenv Pipfile**

This Pipfile will set up the Python environment with the required libraries for the FastAPI sync client.

### **Pipfile**
```toml
[[source]]
name = "pypi"
url = "https://pypi.org/simple"
verify_ssl = true

[packages]
requests = "*"
watchdog = "*"

[requires]
python_version = "3.8"
```

---

## **2. Shell Script**

This script orchestrates the entire process: authentication, identifying the correct pod, port forwarding, and starting the sync client.

### **sync_dev.sh**
```bash
#!/bin/bash

set -e

# --- User-provided arguments ---
NAMESPACE=""
DEV_POD_NAME=""
DEPLOYMENT_SUBNAME="dev-server"  # Default subname for dev deployment
SYNC_ROOT_PATH=$(pwd)           # Default root path (current directory)

# Parse arguments
while [[ "$#" -gt 0 ]]; do
    case $1 in
        -n|--namespace) NAMESPACE="$2"; shift ;;
        -p|--pod-name) DEV_POD_NAME="$2"; shift ;;
        -d|--deployment-subname) DEPLOYMENT_SUBNAME="$2"; shift ;;
        -r|--sync-root) SYNC_ROOT_PATH="$2"; shift ;;
        *) echo "Unknown parameter: $1"; exit 1 ;;
    esac
    shift
done

if [[ -z "$NAMESPACE" || -z "$DEV_POD_NAME" ]]; then
    echo "Error: Namespace (-n) and Pod Name (-p) are required arguments."
    exit 1
fi

# --- Company-specific authentication commands ---
echo "Running company-specific authentication..."
# Fill in your company-specific auth logic here (e.g., SSO, cloud login, etc.)

# --- Step 1: Identify Deployment and Pod ---
echo "Locating the development pod in namespace '$NAMESPACE'..."
DEV_DEPLOYMENT=$(kubectl get deployments -n "$NAMESPACE" \
    --no-headers -o custom-columns=":metadata.name" | grep "$DEPLOYMENT_SUBNAME")

if [[ -z "$DEV_DEPLOYMENT" ]]; then
    echo "Error: No deployment found matching '$DEPLOYMENT_SUBNAME' in namespace '$NAMESPACE'."
    exit 1
fi

POD_NAME=$(kubectl get pods -n "$NAMESPACE" \
    --selector="app=$DEV_DEPLOYMENT" \
    --no-headers -o custom-columns=":metadata.name" | head -n 1)

if [[ -z "$POD_NAME" ]]; then
    echo "Error: No pod found for deployment '$DEV_DEPLOYMENT'."
    exit 1
fi

echo "Found pod: $POD_NAME"

# --- Step 2: Port Forward to the Server ---
LOCAL_PORT=30000
while lsof -i:$LOCAL_PORT >/dev/null 2>&1; do
    ((LOCAL_PORT++))
done

echo "Port forwarding pod '$POD_NAME' to localhost:$LOCAL_PORT..."
kubectl port-forward "$POD_NAME" 8000:$LOCAL_PORT -n "$NAMESPACE" &
PF_PID1=$!

# Wait for port forward to be established
sleep 5

# --- Step 3: Call the Create Pod Endpoint ---
echo "Creating development pod '$DEV_POD_NAME'..."
CREATE_RESPONSE=$(curl -s -X POST "http://localhost:$LOCAL_PORT/create-pod/$DEV_POD_NAME")

if echo "$CREATE_RESPONSE" | grep -q "Pod created successfully"; then
    echo "Development pod '$DEV_POD_NAME' created successfully."
else
    echo "Error: Failed to create development pod. Response: $CREATE_RESPONSE"
    kill $PF_PID1
    exit 1
fi

# --- Step 4: Wait for the Dev Pod and Port Forward ---
echo "Waiting for the development pod to be ready..."
while [[ $(kubectl get pods "$DEV_POD_NAME" -n "$NAMESPACE" -o jsonpath='{.status.phase}') != "Running" ]]; do
    sleep 2
done

LOCAL_PORT2=$((LOCAL_PORT + 1))
echo "Port forwarding to new dev pod '$DEV_POD_NAME' at localhost:$LOCAL_PORT2..."
kubectl port-forward "$DEV_POD_NAME" 8000:$LOCAL_PORT2 -n "$NAMESPACE" &
PF_PID2=$!

# Wait for port forward to be ready
sleep 5

# --- Step 5: Start the Sync Client ---
SYNC_DIR="$SYNC_ROOT_PATH/src"
if [[ ! -d "$SYNC_DIR" ]]; then
    echo "Error: Sync directory '$SYNC_DIR' does not exist."
    kill $PF_PID1 $PF_PID2
    exit 1
fi

echo "Starting sync client to monitor '$SYNC_DIR'..."
pipenv run python client.py --server-port $LOCAL_PORT2 --sync-dir "$SYNC_DIR"

# Cleanup
kill $PF_PID1 $PF_PID2
```

---

## **3. Updated Sync Client**

The sync client now accepts the server port and sync directory as arguments.

### **Updated client.py**
```python
import os
import time
import requests
import argparse
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class FileSyncHandler(FileSystemEventHandler):
    def __init__(self, local_dir, server_url):
        self.local_dir = local_dir
        self.server_url = server_url

    def upload_file(self, file_path):
        relative_path = os.path.relpath(file_path, self.local_dir)
        with open(file_path, "rb") as file:
            response = requests.post(
                f"{self.server_url}/update-file/",
                data={"filepath": relative_path},
                files={"file": file}
            )
            print(f"Uploaded: {relative_path} - {response.status_code}")

    def delete_file(self, file_path):
        relative_path = os.path.relpath(file_path, self.local_dir)
        response = requests.delete(
            f"{self.server_url}/delete-file/",
            data={"filepath": relative_path}
        )
        print(f"Deleted: {relative_path} - {response.status_code}")

    def on_created(self, event):
        if not event.is_directory:
            self.upload_file(event.src_path)

    def on_modified(self, event):
        if not event.is_directory:
            self.upload_file(event.src_path)

    def on_deleted(self, event):
        if not event.is_directory:
            self.delete_file(event.src_path)

def main():
    parser = argparse.ArgumentParser(description="Sync client for file updates")
    parser.add_argument("--server-port", required=True, help="Port the server is running on")
    parser.add_argument("--sync-dir", required=True, help="Directory to monitor for changes")
    args = parser.parse_args()

    server_url = f"http://localhost:{args.server_port}"
    sync_dir = args.sync_dir

    print(f"Monitoring '{sync_dir}' and syncing with server at {server_url}")
    os.makedirs(sync_dir, exist_ok=True)

    # Initial sync
    for root, _, files in os.walk(sync_dir):
        for file in files:
            full_path = os.path.join(root, file)
            FileSyncHandler(sync_dir, server_url).upload_file(full_path)

    # Monitor changes
    event_handler = FileSyncHandler(sync_dir, server_url)
    observer = Observer()
    observer.schedule(event_handler, sync_dir, recursive=True)
    observer.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()

if __name__ == "__main__":
    main()
```

---

## **How to Run**

1. **Install Dependencies**:
   ```bash
   pip install pipenv
   pipenv install
   ```

2. **Run the Script**:
   ```bash
   chmod +x sync_dev.sh
   ./sync_dev.sh -n tenant-namespace -p my-dev-pod -d dev-server -r /path/to/sync
   ```

3. **Sync Directory**:
   - Ensure `/path/to/sync/src` exists.

---

This approach fulfills all requirements, provides flexibility for arguments, and ensures the sync client dynamically uses the correct ports and directories. Let me know if you need further refinements! ðŸš€
